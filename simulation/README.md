# ALCOVE-RL Simulation Pipeline

## Overview
Generates simulated behavioral data using selective value-shaping ALCOVE-RL model. 
The simulated data is outputted in a compatible format so that it can be preprocessed
with the same code that does it for the human behavioral data. 

## Pipeline Structure

### Core Files
- **`alcove_simulation.py`** - Core simulation classes and functions
- **`data_generation.py`** - Data orchestration and JSON generation
- **`generate_simulation_data.py`** - Main run script
- **`test_simulated_data.py`** - Testing script for preprocessing compatibility

## Quick Start

```bash
cd simulation/
python generate_simulation_data.py
python test_simulated_data.py  # Optional: verify compatibility
```

This will:
1. Run 1000 participants through individual learning (phases 0-1)
2. Randomly assign participants to 4 conditions for phases 2-3
3. Generate realistic behavioral data in single JSON file
4. Save data to `outputs/simulated_data.json`

## Experimental Design

### Phase Structure (All Participants)
- **Phase 0**: Individual training (64 trials)
- **Phase 1**: Individual test (32 trials)
- **Phase 2**: Condition-specific training (64 trials)
- **Phase 3**: Condition-specific test (32 trials)

### Conditions (Random Assignment)
1. **Asocial**: Continue individual learning
2. **2D**: Social learning with optimal (2D rule) partner
3. **1d_a**: Social learning with partner using 1D rule (feature 0)
4. **1d_b**: Social learning with partner using 1D rule (feature 1)

## Model Parameters

### ALCOVE-RL
- `c = 6` (specificity constant)
- `phi = 30` (temperature for action selection)  
- `lambda_w = 0.15` (association weight learning rate)
- `lambda_alpha = 0.15` (attention weight learning rate)

### Environment
- 4 binary features per stimulus
- 16 total stimuli (2^4)
- Features [0,1] relevant, dangerous when both = [1,1]
- Rewards: approach safe = +1, approach dangerous = -4, avoid = 0

## Reproducibility

### Random Seed Strategy
- **Single global seed**: 42 (set once at simulation start)
- All randomness proceeds sequentially from this seed
- Ensures perfect reproducibility of entire dataset
- Documented in `simulation_metadata.json`

### Output Structure
```
outputs/
├── simulated_data.json              # All participants, all conditions (single file)
├── simulation_metadata.json         # Full reproducibility info
├── simulated_players_df.csv         # Generated by test script
└── simulated_blocks_df.csv          # Generated by test script
```


# Simulation Data Format Specification

## Overview
Simulation data conforms to a specific JSON format to be compatible with the preprocessing pipeline. The 'sim' version uses the same phase structure as d2 but with simplified field requirements.

## Data Structure

### Top-level structure:
```json
[
  {
    "id": "sim-001",
    "data": { /* participant_data */ }
  },
  {
    "id": "sim-002", 
    "data": { /* participant_data */ }
  },
  {
    "id": "sim-003",
    "data": { /* participant_data */ }
  }
]
```

### participant_data structure (core fields):
```json
{
  "id": "sim-001",
  "recruitment_service": "sim",
  "done": true,
  "points": 150,
  "conditions": {
    "gameType": "solo"   // or "duo"
    // "partnerRule": "2d"  // for duo only: "2d"|"1d_a"|"1d_b"
  },
  "task_data": {
    "0": { /* phase 0 trials */ },
    "1": { /* phase 1 trials */ },
    "2": { /* phase 2 trials */ },
    "3": { /* phase 3 trials */ }
  },
  // Required fields
  "relevantFeatures": [0, 1],           // which features are relevant (0-3)
  "relevantFeaturesBadValues": [1, 1]   // bad values for relevant features
}
```

### task_data structure:
- **Phase 0**: Training (64 trials: "0" to "63")
- **Phase 1**: Test (32 trials: "0" to "31") 
- **Phase 2**: Training (64 trials: "0" to "63")
- **Phase 3**: Test (32 trials: "0" to "31")

Format: `task_data[phase_str][trial_str]`

### Trial data structure:
```json
{
  "trial": 0,
  "pointsPreTrial": 0,
  "pointsPostTrial": 5,
  "stimulusParams": {
    0: 1,  // feature 0 value (0 or 1) - INTEGER KEYS!
    1: 0,  // feature 1 value (0 or 1)
    2: 1,  // feature 2 value (0 or 1)
    3: 0   // feature 3 value (0 or 1)
  },
  "response": "avoid",  // or "approach"
  "approachOutcome": -1,  // -1 for punishing stimuli, +1 for rewarding stimuli
  "partnerResponse": "avoid"  // for duo games only
}
```

### Block structure assumptions:
- Each phase contains phase_blocks[i] blocks (Training: 4 blocks, Test: 2 blocks)
- Each block contains exactly 16 trials
- Trials indexed as: task_data[phase][block*16:(block+1)*16]

## Key Requirements

1. **Recruitment service** must be "sim" (not "prolific")
2. **No questionnaire/recruitment data** - simulation bypasses these
3. **Phase structure** follows d2 format (4 phases, tests at [1,3])
4. **Points tracking** must be consistent: pointsPostTrial[i] = pointsPreTrial[i+1]
5. **String keys** for phases and trials ("0", "1", etc.) not integers
6. **stimulusParams** must have all 4 features as **INTEGER KEYS** (0, 1, 2, 3)
7. **partnerResponse** only for duo games
8. **relevantFeatures** and **relevantFeaturesBadValues** required for decision rule analysis

## Notes
- Fields like `recruitment_info`, `questionnaireQuestions` are not needed
- `external_aid` automatically set to False for simulation
- Partner judgement questions skipped for simulation
- `bonus_points` optional, defaults to None

